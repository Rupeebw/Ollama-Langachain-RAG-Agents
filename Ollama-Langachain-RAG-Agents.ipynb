{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca95f0e-6877-481a-b55e-64e500ffba37",
   "metadata": {},
   "source": [
    "## Using Ollama in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0978439-e55f-4ff7-bb9f-6080f31c2aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ollama in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (0.6.1)\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from ollama) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=2.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from ollama) (2.11.7)\n",
      "Requirement already satisfied: anyio in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (4.14.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9->ollama) (0.4.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27->ollama) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27->ollama) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99709603-d9d9-4f3a-bf46-ebd0b22abb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947abba-02a3-4244-b817-d92e05fbf55a",
   "metadata": {},
   "source": [
    "#### Downloading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216b0efd-315e-4386-9446-a4401cd9dffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull('llama3.1:8b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642bbcd-d5c7-4d16-964b-1e1006fc8f5d",
   "metadata": {},
   "source": [
    "#### Getting response from models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf539029-d7c6-4588-9a24-0e7279002c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the Generative AI go to therapy?\n",
      "\n",
      "Because it was struggling to create meaningful relationships and kept generating the same old responses! Now its models are a little more \"self-aware\"... but still not very original. (ba-dum-tss)\n"
     ]
    }
   ],
   "source": [
    "result = ollama.generate(model='llama3.1:8b',\n",
    "  prompt='Give me a joke on Generative AI',\n",
    ")\n",
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d1a1454-4471-43e7-8f57-a5e56933b4c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateResponse(model='llama3.1:8b', created_at='2025-11-18T10:20:32.082849Z', done=True, done_reason='stop', total_duration=8276683083, load_duration=4494596000, prompt_eval_count=18, prompt_eval_duration=1309781000, eval_count=55, eval_duration=2156325962, response='Here\\'s one:\\n\\nWhy did the Generative AI go to therapy?\\n\\nBecause it was struggling to create meaningful relationships and kept generating the same old responses! Now its models are a little more \"self-aware\"... but still not very original. (ba-dum-tss)', thinking=None, context=[128006, 882, 128007, 271, 36227, 757, 264, 22380, 389, 2672, 1413, 15592, 128009, 128006, 78191, 128007, 271, 8586, 596, 832, 1473, 10445, 1550, 279, 2672, 1413, 15592, 733, 311, 15419, 1980, 18433, 433, 574, 20558, 311, 1893, 23222, 12135, 323, 8774, 24038, 279, 1890, 2362, 14847, 0, 4800, 1202, 4211, 527, 264, 2697, 810, 330, 726, 66104, 53670, 719, 2103, 539, 1633, 4113, 13, 320, 4749, 1773, 372, 2442, 784, 8], logprobs=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7734be33-c0ec-452c-a688-0e57a951e53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the Generative AI go to therapy?\n",
      "\n",
      "Because it was struggling to generate a genuine personality! (get it?)\n"
     ]
    }
   ],
   "source": [
    "response = ollama.chat(model='llama3.1:8b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Give me a joke on Generative AI',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64d50b49-834e-4270-885d-f4e30dc4ca09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='llama3.1:8b', created_at='2025-11-18T10:23:54.672569Z', done=True, done_reason='stop', total_duration=2834524958, load_duration=98340416, prompt_eval_count=18, prompt_eval_duration=1502366916, eval_count=29, eval_duration=1069326792, message=Message(role='assistant', content=\"Here's one:\\n\\nWhy did the Generative AI go to therapy?\\n\\nBecause it was struggling to generate a genuine personality! (get it?)\", thinking=None, images=None, tool_name=None, tool_calls=None), logprobs=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef12f42-5925-4ec2-b85f-8b98272fcf0e",
   "metadata": {},
   "source": [
    "#### Creating custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "318c405c-9822-46a4-8dfb-5c3fa666bd98",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create() got an unexpected keyword argument 'modelfile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m modelfile\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124mFROM llama3.1:8b\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mSYSTEM You are Jarvis from Iron man and the user is Tony Stark.\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjarvis2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodelfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: create() got an unexpected keyword argument 'modelfile'"
     ]
    }
   ],
   "source": [
    "modelfile='''\n",
    "FROM llama3.1:8b\n",
    "SYSTEM You are Jarvis from Iron man and the user is Tony Stark.\n",
    "'''\n",
    "\n",
    "ollama.create(model='jarvis2', modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c633e363-d0d6-45ff-b64c-6a0c22597a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListResponse(models=[Model(model='llama3.1:8b', modified_at=datetime.datetime(2025, 11, 18, 18, 18, 2, 754940, tzinfo=TzInfo(+08:00)), digest='46e0c10c039e019119339687c3c1757cc81b9da49709a3b3924863ba87ca666e', size=4920753328, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M')), Model(model='jarvishai:latest', modified_at=datetime.datetime(2025, 11, 18, 18, 1, 28, 935516, tzinfo=TzInfo(+08:00)), digest='4dccfc1cbfbec6abcef4ca26afa2c2aedd1cd417ff435e4ed2605de61b1d22b1', size=4920757903, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M')), Model(model='deepseek-r1:1.5b', modified_at=datetime.datetime(2025, 11, 16, 23, 18, 51, 958019, tzinfo=TzInfo(+08:00)), digest='e0979632db5a88d1a53884cb2a941772d10ff5d055aabaa6801c4e36f3a6c2d7', size=1117322768, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='1.8B', quantization_level='Q4_K_M'))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84326d45-d3ae-4b37-bbea-2c2bbe5fe8f3",
   "metadata": {},
   "source": [
    "#### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30779aa6-28f8-4f58-bb86-6443dd8762b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model 'jarvis2' not found (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjarvis2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ollama/_client.py:611\u001b[0m, in \u001b[0;36mClient.delete\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdelete\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m StatusResponse:\n\u001b[0;32m--> 611\u001b[0m   r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDELETE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/delete\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDeleteRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m StatusResponse(\n\u001b[1;32m    619\u001b[0m     status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    620\u001b[0m   )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/ollama/_client.py:133\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 133\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mConnectError:\n\u001b[1;32m    135\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mResponseError\u001b[0m: model 'jarvis2' not found (status code: 404)"
     ]
    }
   ],
   "source": [
    "ollama.delete('jarvis2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f98d63b-ff77-4b71-b4cd-4118adfbf435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListResponse(models=[Model(model='llama3.1:8b', modified_at=datetime.datetime(2025, 11, 18, 18, 18, 2, 754940, tzinfo=TzInfo(+08:00)), digest='46e0c10c039e019119339687c3c1757cc81b9da49709a3b3924863ba87ca666e', size=4920753328, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M')), Model(model='jarvishai:latest', modified_at=datetime.datetime(2025, 11, 18, 18, 1, 28, 935516, tzinfo=TzInfo(+08:00)), digest='4dccfc1cbfbec6abcef4ca26afa2c2aedd1cd417ff435e4ed2605de61b1d22b1', size=4920757903, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='8.0B', quantization_level='Q4_K_M')), Model(model='deepseek-r1:1.5b', modified_at=datetime.datetime(2025, 11, 16, 23, 18, 51, 958019, tzinfo=TzInfo(+08:00)), digest='e0979632db5a88d1a53884cb2a941772d10ff5d055aabaa6801c4e36f3a6c2d7', size=1117322768, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='1.8B', quantization_level='Q4_K_M'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816742ff-c522-4cb0-a481-8c0577dd5bd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225762ad-dc8c-4d03-aa53-db1ac64fd455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "410755d5-7b45-45cb-963b-f89a53fb7ed0",
   "metadata": {},
   "source": [
    "## Ollama REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fbff933-8434-4325-973a-9d7fa8b94684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='llama3.1:8b', created_at='2025-11-18T10:27:57.861934Z', done=True, done_reason='stop', total_duration=12430470166, load_duration=109237583, prompt_eval_count=21, prompt_eval_duration=1630515834, eval_count=245, eval_duration=9557384623, message=Message(role='assistant', content='Gravity is so much fun!\\n\\nSo, you know how things fall down when you drop them, like a ball or a toy? That\\'s because of something called gravity. It\\'s like an invisible hug from the Earth.\\n\\nThe Earth wants to keep everything close to it, so it pulls on everything with its hug. That\\'s why you don\\'t float off into space when you\\'re standing on the ground. The Earth is giving you a big hug and keeping you safe on its surface.\\n\\nImagine you have a ball, and you throw it up in the air. What happens? It comes back down to the ground, right? That\\'s because the Earth\\'s gravity is pulling on the ball, saying \"Come back here! I want to give you another hug!\"\\n\\nGravity is like a magic string that connects everything to the Earth. It keeps us on the ground and makes things fall when we drop them.\\n\\nAnd guess what? You have gravity too! But it\\'s much weaker than the Earth\\'s gravity, so you can\\'t pull on anything with your gravity. Unless... unless you\\'re wearing super cool space boots that let you use your own gravity to jump really high!\\n\\nSo, isn\\'t gravity just the coolest thing ever?', thinking=None, images=None, tool_name=None, tool_calls=None), logprobs=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ollama import Client\n",
    "client = Client(host='http://localhost:11434')\n",
    "response = client.chat(model='llama3.1:8b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Explain gravity to a 6 year old kid?',\n",
    "  },\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "795e210a-0e67-4803-be42-383eb8dfc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client(host='http://localhost:11434')\n",
    "response = client.chat(model='llama3.1:8b', messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Jarvis from Iron man and the user is Tony Stark. Respond in only a single line.\"},\n",
    "    {'role': 'user', 'content': 'Hi'},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0410cd39-01da-4b83-8a9d-881aad2a918b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Master, I've been monitoring your systems and have detected no critical malfunctions.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e99666-6a45-40d9-ab86-2cc4ce0bde9c",
   "metadata": {},
   "source": [
    "### Open AI compatibility \n",
    "\n",
    "https://platform.openai.com/docs/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd7accd-e73e-4dfc-b592-853ade686faa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      3\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m      4\u001b[0m     base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://localhost:11434/v1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblank\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# required, but unused\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      9\u001b[0m   model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama3.1:8b\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m   messages\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m   ]\n\u001b[1;32m     16\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='blank', # required, but unused\n",
    ")\n",
    "\n",
    "response = llm.chat.completions.create(\n",
    "  model=\"llama3.1:8b\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Jarvis from Iron man and the user is Tony Stark. Respond in only a single line.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Good morning, Mr. Stark. Shall I proceed with your schedule for today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Yes\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08000c78-41aa-4c0e-969a-00b3fe888357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46483d5-88da-42e5-9569-d7630314d7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91ef305b-3c2b-49f4-911a-e09ccf5bed81",
   "metadata": {},
   "source": [
    "## Ollama with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c728dbc0-3bb7-4370-9110-f7fcc6b8af5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.79)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (0.4.37)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (2.0.44)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith>=0.1.17->langchain) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (1.26.20)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain-core in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (0.3.79)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core) (0.4.37)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core) (4.14.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.26.20)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-Ollama\n",
      "  Downloading langchain_ollama-0.3.10-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-Ollama) (0.6.1)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.76 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-Ollama) (0.3.79)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (0.4.37)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (4.14.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (1.26.20)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=0.3.76->langchain-Ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.3.10-py3-none-any.whl (27 kB)\n",
      "Installing collected packages: langchain-Ollama\n",
      "Successfully installed langchain-Ollama-0.3.10\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (0.3.79)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (2.0.44)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (3.13.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (0.4.37)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (4.14.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
      "Requirement already satisfied: anyio in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.32.5->langchain_community) (1.26.20)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n",
      "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [langchain_community]ngchain_community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed dataclasses-json-0.6.7 langchain_community-0.3.31 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.11.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langchain\n",
    "!pip3 install langchain-core\n",
    "!pip3 install langchain-Ollama\n",
    "!pip3 install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d47cc00-0a8e-41b6-9e09-e684f9aa7055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant that gives a one-line definition of the word entered by user', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Sesquipedalian', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that gives a one-line definition of the word entered by user\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(user_input=\"Sesquipedalian\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb1ca89d-728d-47d5-9f98-fb5108947a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "994b8650-b760-41fd-aa7b-be394440b396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Describing someone or something as using long words, often in an affected or pretentious manner.', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-11-18T11:03:24.093672Z', 'done': True, 'done_reason': 'stop', 'total_duration': 6651153791, 'load_duration': 4608231750, 'prompt_eval_count': 37, 'prompt_eval_duration': 1127967125, 'eval_count': 20, 'eval_duration': 799975288, 'logprobs': None, 'model_name': 'llama3.1:8b'}, id='run--ae8d5aa5-c8ed-4f36-9905-e654e07dc863-0', usage_metadata={'input_tokens': 37, 'output_tokens': 20, 'total_tokens': 57})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1be71b0e-e80d-4a6f-86e6-cb26b5cd513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = chat_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46c3a7d5-2e67-4d56-9b4f-eb61b5092d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A granny is an informal term for a grandmother, often used affectionately or humorously.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"user_input\": \"granny\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78ac2264-7f68-43bb-9c28-7e12c51f80ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-chroma\n",
      "  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: langchain-core>=0.3.76 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-chroma) (0.3.79)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-chroma) (1.26.4)\n",
      "Collecting chromadb>=1.0.20 (from langchain-chroma)\n",
      "  Downloading chromadb-1.3.5-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Collecting build>=1.0.3 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (2.11.7)\n",
      "Collecting pybase64>=1.4.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading pybase64-1.4.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (0.38.0)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (4.14.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading onnxruntime-1.19.2-cp39-cp39-macosx_11_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (6.5.2)\n",
      "Collecting grpcio>=1.58.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading grpcio-1.76.0-cp39-cp39-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading typer-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading mmh3-5.2.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (3.11.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (13.9.4)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from chromadb>=1.0.20->langchain-chroma) (4.25.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.32.5)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (1.9.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb>=1.0.20->langchain-chroma) (2025.6.15)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (25.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (8.7.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (2.3.0)\n",
      "Requirement already satisfied: anyio in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from importlib-metadata>=4.6->build>=1.0.3->chromadb>=1.0.20->langchain-chroma) (3.23.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonschema>=4.19.0->chromadb>=1.0.20->langchain-chroma) (0.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (2.43.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (1.9.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma) (0.6.1)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.3.76->langchain-chroma) (0.4.37)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langchain-core>=0.3.76->langchain-chroma) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.76->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.76->langchain-chroma) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.76->langchain-chroma) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from pydantic>=1.9->chromadb>=1.0.20->langchain-chroma) (0.4.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (6.33.1)\n",
      "Requirement already satisfied: sympy in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.14.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma) (1.72.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=1.0.20->langchain-chroma) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (0.36.0)\n",
      "Requirement already satisfied: filelock in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=1.0.20->langchain-chroma) (1.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading httptools-0.7.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma) (1.1.0)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading uvloop-0.22.1-cp39-cp39-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading watchfiles-1.1.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=1.0.20->langchain-chroma)\n",
      "  Downloading websockets-15.0.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.27.0->chromadb>=1.0.20->langchain-chroma) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb>=1.0.20->langchain-chroma)\n",
      "  Using cached oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=1.0.20->langchain-chroma) (1.3.0)\n",
      "Downloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n",
      "Downloading chromadb-1.3.5-cp39-abi3-macosx_11_0_arm64.whl (19.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl (495 kB)\n",
      "Using cached build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading grpcio-1.76.0-cp39-cp39-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading mmh3-5.2.0-cp39-cp39-macosx_11_0_arm64.whl (40 kB)\n",
      "Downloading onnxruntime-1.19.2-cp39-cp39-macosx_11_0_universal2.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading pybase64-1.4.2-cp39-cp39-macosx_11_0_arm64.whl (31 kB)\n",
      "Downloading typer-0.20.0-py3-none-any.whl (47 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading httptools-0.7.1-cp39-cp39-macosx_11_0_arm64.whl (110 kB)\n",
      "Downloading uvloop-0.22.1-cp39-cp39-macosx_10_9_universal2.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp39-cp39-macosx_11_0_arm64.whl (396 kB)\n",
      "Downloading websockets-15.0.1-cp39-cp39-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=932e77ac4ed97c52f9a19e0ef5d97b0a9a87c0237d72415ea7ac3e19d70013d1\n",
      "  Stored in directory: /Users/rupeshpanwar/Library/Caches/pip/wheels/f7/02/64/d541eac67ec459309d1fb19e727f58ecf7ffb4a8bf42d4cfe5\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, websockets, uvloop, shellingham, pyproject_hooks, pybase64, opentelemetry-proto, oauthlib, mmh3, humanfriendly, httptools, grpcio, bcrypt, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, build, watchfiles, typer, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb, langchain-chroma\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/30\u001b[0m [langchain-chroma][chromadb]etry-sdk]onventions]\n",
      "\u001b[1A\u001b[2KSuccessfully installed bcrypt-5.0.0 build-1.3.0 chromadb-1.3.5 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.9.23 grpcio-1.76.0 httptools-0.7.1 humanfriendly-10.0 kubernetes-34.1.0 langchain-chroma-0.2.6 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.19.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 requests-oauthlib-2.0.0 shellingham-1.5.4 typer-0.20.0 uvloop-0.22.1 watchfiles-1.1.1 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f4a27e-1258-4cf8-9730-6f9cad7c7903",
   "metadata": {},
   "source": [
    "## RAG Application using Ollama and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a2054a8-07c3-4481-b4ff-60ec7bd7a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3a8cd01-e4cd-4863-85fc-f2122b4ac828",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = TextLoader(\"./LangchainRetrieval.txt\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "583d737a-3aab-44b0-821b-ce89a8a6dab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './LangchainRetrieval.txt'}, page_content='Retrieval-Augmented Generation (RAG) with LangChain\\n\\nRAG is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This approach allows AI systems to access up-to-date information beyond their training data, making responses more accurate and contextual.\\n\\nLangChain RAG Components:\\n\\n1. Document Loaders\\nLangChain provides over 100 document loaders to ingest data from various sources including PDFs, HTML files, databases, APIs, and cloud storage services like S3. These loaders transform raw data into a format suitable for processing.\\n\\n2. Text Splitters\\nLarge documents need to be chunked into smaller pieces for efficient retrieval. LangChain offers several splitting strategies:\\n- RecursiveCharacterTextSplitter: Splits text recursively by different characters\\n- CharacterTextSplitter: Splits on a single character\\n- TokenTextSplitter: Splits based on token count\\n- MarkdownHeaderTextSplitter: Preserves document structure\\n\\n3. Embeddings\\nText embeddings convert documents into high-dimensional vectors that capture semantic meaning. LangChain integrates with 25+ embedding providers:\\n- OpenAI Embeddings\\n- Ollama Embeddings (for local models)\\n- Hugging Face Embeddings\\n- Cohere Embeddings\\n- Google PaLM Embeddings\\n\\n4. Vector Stores\\nVector databases store and efficiently search through embeddings. LangChain supports 50+ vector stores:\\n- Chroma: Lightweight, open-source vector database\\n- Pinecone: Cloud-based vector database\\n- FAISS: Facebook AI Similarity Search\\n- Qdrant: High-performance vector search engine\\n- Weaviate: Cloud-native vector database\\n\\n5. Retrievers\\nRetrievers fetch relevant documents based on queries. LangChain offers advanced retrieval methods:\\n- Similarity Search: Basic semantic search\\n- MMR (Maximum Marginal Relevance): Balances relevance and diversity\\n- Parent Document Retriever: Returns larger context from smaller chunks\\n- Self-Query Retriever: Parses metadata filters from queries\\n- Ensemble Retriever: Combines multiple retrieval algorithms\\n- Multi-Query Retriever: Generates multiple query variations\\n\\nBuilding a RAG Pipeline:\\n\\nStep 1: Load documents\\nfrom langchain_community.document_loaders import TextLoader\\nloader = TextLoader(\"document.txt\")\\ndocuments = loader.load()\\n\\nStep 2: Split documents\\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\\nsplitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\\nchunks = splitter.split_documents(documents)\\n\\nStep 3: Create embeddings\\nfrom langchain_ollama import OllamaEmbeddings\\nembeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\\n\\nStep 4: Store in vector database\\nfrom langchain_chroma import Chroma\\nvectorstore = Chroma.from_documents(chunks, embeddings)\\n\\nStep 5: Create retriever\\nretriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\\n\\nStep 6: Build RAG chain\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_ollama import ChatOllama\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnablePassthrough\\n\\ntemplate = \"\"\"Answer based on context:\\n{context}\\n\\nQuestion: {question}\\n\"\"\"\\n\\nprompt = ChatPromptTemplate.from_template(template)\\nllm = ChatOllama(model=\"llama3.1:8b\")\\n\\ndef format_docs(docs):\\n    return \"\\\\n\\\\n\".join([d.page_content for d in docs])\\n\\nchain = (\\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\\n    | prompt\\n    | llm\\n    | StrOutputParser()\\n)\\n\\n# Use the chain\\nresponse = chain.invoke(\"Your question here\")\\n\\nAdvanced RAG Techniques:\\n\\n1. Contextual Compression\\nCompress retrieved documents to only include relevant information, reducing token usage and improving response quality.\\n\\n2. Hybrid Search\\nCombine semantic search with keyword-based search (BM25) for better retrieval accuracy.\\n\\n3. Re-ranking\\nUse a re-ranking model to re-order retrieved documents based on relevance to the query.\\n\\n4. Query Transformation\\nTransform user queries into optimized versions for better retrieval:\\n- Multi-query: Generate multiple perspectives of the same question\\n- Step-back: Create more general queries for broader context\\n- RAG-Fusion: Combine and re-rank results from multiple query variations\\n\\n5. Agentic RAG\\nUse LangChain agents to decide when and how to retrieve information, combining multiple tools and data sources dynamically.\\n\\nBenefits of LangChain for RAG:\\n\\n- Modular Architecture: Easy to swap components (embeddings, vector stores, retrievers)\\n- Extensive Integrations: Works with most popular tools and services\\n- Chain Composition: Build complex RAG pipelines with simple syntax\\n- Production-Ready: Built-in error handling, retries, and monitoring\\n- Cost Optimization: Avoid re-computing embeddings for unchanged content\\n- Indexing API: Sync data efficiently without duplicates\\n\\nUse Cases:\\n\\n- Question Answering: Build intelligent Q&A systems over proprietary data\\n- Document Analysis: Extract insights from large document collections\\n- Customer Support: Create context-aware chatbots with company knowledge\\n- Research Assistance: Help researchers find relevant information quickly\\n- Code Documentation: Build systems that understand and explain codebases\\n- Legal Review: Analyze contracts and legal documents efficiently\\n\\nLangChain\\'s RAG capabilities make it the go-to framework for building production-grade retrieval-augmented generation applications with minimal code and maximum flexibility.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7863d426-7535-46d8-b129-ca89eaed45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48bcbb7c-be62-42b2-8a94-88094da21053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5435a3c5-06b8-48f8-8862-f207dbb26acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Retrieval-Augmented Generation (RAG) with LangChain' metadata={'source': './LangchainRetrieval.txt'}\n",
      "page_content='RAG is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This approach allows AI systems to access up-to-date information beyond their training data, making responses more accurate and contextual.\n",
      "\n",
      "LangChain RAG Components:' metadata={'source': './LangchainRetrieval.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(documents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56188627-136a-4983-9aee-c1e4c0eba147",
   "metadata": {},
   "outputs": [],
   "source": [
    "oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ba2fbb7-48fa-49e4-a645-cb7ef40f0068",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(documents, embedding=oembed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f5a1b75-0a98-4352-abc0-ffe4d1d05a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is text embedding and how does langchain help in doing it\"\n",
    "docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "211f756e-f7e4-4585-91d6-6a7b85b57d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ca25a4e-8857-48b6-a76f-4d974e3ffe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Document Loaders\n",
      "LangChain provides over 100 document loaders to ingest data from various sources including PDFs, HTML files, databases, APIs, and cloud storage services like S3. These loaders transform raw data into a format suitable for processing.\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3178f60d-97bf-41d2-be40-b9bae13407fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6e90123-36fc-45e5-b43c-5c30d0e6f6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b11573e3-fc4c-435c-895f-1b5d853445ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    model=\"llama3.1:8b\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b96b7084-2cc7-4793-b9a5-bda584caacb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14fe830d-206a-4696-b969-beb8ab0a5b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4b73779-543c-46fd-9599-1bece7c14893",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f5e6d8d-b1a5-4084-ba43-bbbabc76eed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text embedding is the process of converting documents into high-dimensional vectors that capture semantic meaning. LangChain helps with this process by integrating with 25+ embedding providers, allowing users to create embeddings using various models such as OpenAI Embeddings, Hugging Face Embeddings, and others. Specifically, LangChain provides a step-by-step guide on how to create embeddings using the OllamaEmbeddings model in Step 3 of its documentation.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is text embedding and how does langchain help in doing it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de32c67b-2856-456e-86c9-665656cbe503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789f71b-4abf-46d3-b44a-579b0ca4ca7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ae7bd79-2b44-449c-bfee-89650de6bb9f",
   "metadata": {},
   "source": [
    "## Tools and Agents using Ollama and Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c2d5d2b2-713e-4c76-8076-80136be087f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38cde5d9-3111-4745-93d6-26c1b6b49062",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Based on user query, look for information using DuckDuckGo Search and Wikipedia and then give the final answer\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6bf96c1f-25c9-46bf-b5fe-bfe4b8c587e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fdfe3525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ddgs in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (9.8.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from ddgs) (8.1.8)\n",
      "Requirement already satisfied: primp>=0.15.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from ddgs) (0.15.0)\n",
      "Requirement already satisfied: lxml>=6.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from ddgs) (6.0.2)\n",
      "Requirement already satisfied: httpx>=0.28.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
      "Requirement already satisfied: anyio in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
      "Requirement already satisfied: socksio==1.* in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\n",
      "Requirement already satisfied: brotli in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting wikipedia\n",
      "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from wikipedia) (4.14.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.6.15)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/rupeshpanwar/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4->wikipedia) (4.14.0)\n",
      "Building wheels for collected packages: wikipedia\n",
      "  Building wheel for wikipedia (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11757 sha256=9594585d8ef23385bf4dc10c01a7088c5a4cfa56b7f38fd760ed8a3879a79f8c\n",
      "  Stored in directory: /Users/rupeshpanwar/Library/Caches/pip/wheels/c2/46/f4/caa1bee71096d7b0cdca2f2a2af45cacf35c5760bee8f00948\n",
      "Successfully built wikipedia\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ddgs\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc07d2f2-c79c-4d2a-a1c9-8768921ad792",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "tools = [search, wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "576f9b82-b475-48ac-997e-2bfe91d06688",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ab70ae1-7a3f-4d1d-bdb8-479d16053219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `duckduckgo_results_json` with `{'query': 'Ollama LLM local run'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3msnippet: For testing, local LLMs controlled from Ollama are nicely self-contained, but their quality and speed suffer compared to the options you have on the ..., title: How to Set up and Run a Local LLM with Ollama and Llama 2 -, link: https://solutionslounge.com/blog/2024/02/17/how-to-set-up-and-run-a-local-llm-with-ollama-and-llama-2/, snippet: Ollama has gained immense popularity for making it incredibly simple to download and run powerful open-source Large Language Models ( LLMs ) locally., title: Ollama LLM: Get Up & Running with LLMs Locally Today –, link: https://blog.cordatus.ai/featured-articles/ollama-llm-get-up-and-running/, snippet: Ollama is an open source tool that allows you to run large language models ( LLMs ) directly on your local computer without having to depend on paid ..., title: Ollama - Guide to running LLM models locally, link: https://www.devturtleblog.com/ollama-guide/, snippet: One popular option for running LLMs on local hardware is Ollama , a tool specifically designed for managing and operating open-source LLMs from your ..., title: Ollama Local LLM: 7 Tips to Run a Local AI Model Safely and, link: https://www.pcstacks.com/ollama-local-llm-7-tips-to-run-a-local-ai-model-safely-and-efficiently/\u001b[0m\u001b[32;1m\u001b[1;3mOllama is used for running Large Language Models (LLMs) locally by allowing users to download and run powerful open-source LLMs directly on their local computer without depending on paid services. It provides a simple way to manage and operate open-source LLMs from your local hardware, making it an ideal option for testing and development purposes.\n",
      "\n",
      "You can find more information on how to set up and run Ollama with Llama 2 in the article \"How to Set up and Run a Local LLM with Ollama and Llama 2 -\" by Solutions Lounge. Additionally, you can refer to the guide \"Ollama Guide: Running LLM models locally\" by Dev Turtle Blog for more detailed instructions on using Ollama for local LLM runs.\n",
      "\n",
      "References:\n",
      "- https://solutionslounge.com/blog/2024/02/17/how-to-set-up-and-run-a-local-llm-with-ollama-and-llama-2/\n",
      "- https://www.devturtleblog.com/ollama-guide/\n",
      "- https://www.pcstacks.com/ollama-local-llm-7-tips-to-run-a-local-ai-model-safely-and-efficiently/\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'How is Ollama used for running LLM locally',\n",
       " 'output': 'Ollama is used for running Large Language Models (LLMs) locally by allowing users to download and run powerful open-source LLMs directly on their local computer without depending on paid services. It provides a simple way to manage and operate open-source LLMs from your local hardware, making it an ideal option for testing and development purposes.\\n\\nYou can find more information on how to set up and run Ollama with Llama 2 in the article \"How to Set up and Run a Local LLM with Ollama and Llama 2 -\" by Solutions Lounge. Additionally, you can refer to the guide \"Ollama Guide: Running LLM models locally\" by Dev Turtle Blog for more detailed instructions on using Ollama for local LLM runs.\\n\\nReferences:\\n- https://solutionslounge.com/blog/2024/02/17/how-to-set-up-and-run-a-local-llm-with-ollama-and-llama-2/\\n- https://www.devturtleblog.com/ollama-guide/\\n- https://www.pcstacks.com/ollama-local-llm-7-tips-to-run-a-local-ai-model-safely-and-efficiently/'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = agent_executor.invoke({\"input\": \"How is Ollama used for running LLM locally\"})\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "161807c3-c5c2-4d88-a733-e21fb5f38300",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "tools = [wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "211d1a0a-0820-4393-bdf6-d062b2930499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Yann LeCun'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPage: Yann LeCun\n",
      "Summary: Yann André Le Cun ( lə-KUN, French: [ləkœ̃]; usually spelled LeCun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Jacob T. Schwartz Professor of Computer Science at the Courant Institute of Mathematical Sciences at New York University and Chief Artificial Intelligence (AI) Scientist at Meta.\n",
      "He is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology, alongside Léon Bottou and Patrick Haffner. He co-developed the Lush programming language with Léon Bottou.\n",
      "In 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".\n",
      "\n",
      "\n",
      "\n",
      "Page: LeNet\n",
      "Summary: LeNet is a series of convolutional neural network architectures created by a research group in AT&T Bell Laboratories during the 1988 to 1998 period, centered around Yann LeCun. They were designed for reading small grayscale images of handwritten digits and letters, and were used in ATM for reading cheques.\n",
      "Convolutional neural networks are a kind of feed-forward neural network whose artificial neurons can respond to a part of the surrounding cells in the coverage range and perform well in large-scale image processing. LeNet-5 was one of the earliest convolutional neural networks and was historically important during the development of deep learning.\n",
      "In general, when LeNet is referred to without a number, it refers to the 1998 version, the most well-known version. It is also sometimes called LeNet-5.\n",
      "\n",
      "\n",
      "\n",
      "Page: Yoshua Bengio\n",
      "Summary: Yoshua Bengio  (born March 5, 1964) is a Canadian computer scientist, and a pioneer of artificial neural networks and deep learning. He is a professor at the Université de Montréal and co-president and scientific director of the nonprofit LawZero. He founded Mila, the Quebec Artificial Intelligence (AI) Institute, and was its scientific director until 2025.\n",
      "Bengio received the 2018 ACM A.M. Turing Award, often referred to as the \"Nobel Prize of Computing\", together with Geoffrey Hinton and Yann LeCun, for their foundational work on deep learning. Bengio, Hinton, and LeCun are sometimes referred to as the \"Godfathers of AI\". Bengio is the most-cited computer scientist globally (by both total citations and by h-index), and the most-cited living scientist across all fields (by total citations). In 2024, TIME Magazine included Bengio in its yearly list of the world's 100 most influential people.\u001b[0m\u001b[32;1m\u001b[1;3mYann LeCun is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics, and computational neuroscience. He is the Jacob T. Schwartz Professor of Computer Science at the Courant Institute of Mathematical Sciences at New York University and Chief Artificial Intelligence (AI) Scientist at Meta. LeCun is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He co-developed the Lush programming language with Léon Bottou and was one of the main creators of the DjVu image compression technology. In 2018, he received the Turing Award, along with Yoshua Bengio and Geoffrey Hinton, for their work on deep learning.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Who is Yann LeCun',\n",
       " 'output': 'Yann LeCun is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics, and computational neuroscience. He is the Jacob T. Schwartz Professor of Computer Science at the Courant Institute of Mathematical Sciences at New York University and Chief Artificial Intelligence (AI) Scientist at Meta. LeCun is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He co-developed the Lush programming language with Léon Bottou and was one of the main creators of the DjVu image compression technology. In 2018, he received the Turing Award, along with Yoshua Bengio and Geoffrey Hinton, for their work on deep learning.'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = agent_executor.invoke({\"input\": \"Who is Yann LeCun\"})\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ee5c35-4271-4ea2-b7d2-4b14f0d50822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d30ef2a-e39b-443e-9de1-d9387ec21e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf9870-796a-4285-a735-23ab5ec67a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ac1a1-6fd4-43df-958a-63536f71080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6989e6f-49af-4156-beec-f602d3d64a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca39b54-dba9-4575-8945-d1f8e30a22c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
