{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Tools and Agents using Ollama and LangChain\n",
    "\n",
    "This notebook demonstrates building AI agents that can use external tools to answer questions:\n",
    "- Creating custom tools (DuckDuckGo Search, Wikipedia)\n",
    "- Building agents with tool-calling capabilities\n",
    "- Using AgentExecutor for orchestration\n",
    "- Real-world examples of information retrieval\n",
    "\n",
    "## What are Agents?\n",
    "Agents are LLM-powered systems that can decide which tools to use and when to use them based on user queries. They can chain multiple tool calls together to solve complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-base",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install langchain\n",
    "!pip3 install langchain-core\n",
    "!pip3 install langchain-ollama\n",
    "!pip3 install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-tools",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ddgs\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7bd79-2b44-449c-bfee-89650de6bb9f",
   "metadata": {},
   "source": [
    "## Building Tools and Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "### Import Required Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5d2b2-713e-4c76-8076-80136be087f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-setup",
   "metadata": {},
   "source": [
    "### Create Agent Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cde5d9-3111-4745-93d6-26c1b6b49062",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Based on user query, look for information using DuckDuckGo Search and Wikipedia and then give the final answer\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-setup",
   "metadata": {},
   "source": [
    "### Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf96c1f-25c9-46bf-b5fe-bfe4b8c587e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-setup",
   "metadata": {},
   "source": [
    "## Example 1: Using DuckDuckGo and Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-tools",
   "metadata": {},
   "source": [
    "### Create Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc07d2f2-c79c-4d2a-a1c9-8768921ad792",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "tools = [search, wikipedia]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-agent",
   "metadata": {},
   "source": [
    "### Create Agent and Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f9b82-b475-48ac-997e-2bfe91d06688",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example1",
   "metadata": {},
   "source": [
    "### Example Query: How is Ollama used for running LLM locally?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab70ae1-7a3f-4d1d-bdb8-479d16053219",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = agent_executor.invoke({\"input\": \"How is Ollama used for running LLM locally\"})\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2-header",
   "metadata": {},
   "source": [
    "## Example 2: Using Wikipedia Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wiki-only",
   "metadata": {},
   "source": [
    "### Create Wikipedia-only Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161807c3-c5c2-4d88-a733-e21fb5f38300",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()\n",
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "tools = [wikipedia]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example2",
   "metadata": {},
   "source": [
    "### Example Query: Who is Yann LeCun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d1a0a-0820-4393-bdf6-d062b2930499",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = agent_executor.invoke({\"input\": \"Who is Yann LeCun\"})\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## How Agents Work\n",
    "\n",
    "When you run an agent:\n",
    "\n",
    "1. **Query Analysis**: The agent analyzes the user's question\n",
    "2. **Tool Selection**: Decides which tool(s) to use (DuckDuckGo, Wikipedia, etc.)\n",
    "3. **Tool Execution**: Calls the selected tool(s) with appropriate parameters\n",
    "4. **Response Synthesis**: Combines tool outputs with its knowledge to generate a final answer\n",
    "5. **Iteration**: Can make multiple tool calls if needed to answer complex questions\n",
    "\n",
    "The `verbose=True` parameter shows the agent's reasoning process and tool calls in the output.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "- **Tools**: External functions the agent can call (search engines, APIs, databases, etc.)\n",
    "- **Agent**: The decision-making component powered by the LLM\n",
    "- **AgentExecutor**: Orchestrates the agent's execution and tool calls\n",
    "- **Prompt Template**: Defines the agent's behavior and instructions\n",
    "\n",
    "## Benefits of Tool-Calling Agents\n",
    "\n",
    "- Access to real-time information beyond training data\n",
    "- Ability to perform actions (search, calculations, API calls)\n",
    "- More accurate and up-to-date responses\n",
    "- Flexible tool combinations for different use cases\n",
    "- Transparent reasoning with verbose mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
