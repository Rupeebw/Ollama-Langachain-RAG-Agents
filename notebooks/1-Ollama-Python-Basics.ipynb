{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca95f0e-6877-481a-b55e-64e500ffba37",
   "metadata": {},
   "source": [
    "# Using Ollama in Python\n",
    "\n",
    "This notebook covers the basics of using Ollama with Python, including:\n",
    "- Installing and importing Ollama\n",
    "- Downloading models\n",
    "- Getting responses from models\n",
    "- Creating custom models\n",
    "- Using Ollama REST API\n",
    "- OpenAI compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "installation",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0978439-e55f-4ff7-bb9f-6080f31c2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99709603-d9d9-4f3a-bf46-ebd0b22abb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e947abba-02a3-4244-b817-d92e05fbf55a",
   "metadata": {},
   "source": [
    "## Downloading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b0efd-315e-4386-9446-a4401cd9dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama.pull('llama3.1:8b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8642bbcd-d5c7-4d16-964b-1e1006fc8f5d",
   "metadata": {},
   "source": [
    "## Getting response from models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generate-method",
   "metadata": {},
   "source": [
    "### Using generate() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf539029-d7c6-4588-9a24-0e7279002c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ollama.generate(model='llama3.1:8b',\n",
    "  prompt='Give me a joke on Generative AI',\n",
    ")\n",
    "print(result['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1a1454-4471-43e7-8f57-a5e56933b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chat-method",
   "metadata": {},
   "source": [
    "### Using chat() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7734be33-c0ec-452c-a688-0e57a951e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(model='llama3.1:8b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Give me a joke on Generative AI',\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d50b49-834e-4270-885d-f4e30dc4ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef12f42-5925-4ec2-b85f-8b98272fcf0e",
   "metadata": {},
   "source": [
    "## Creating custom models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318c405c-9822-46a4-8dfb-5c3fa666bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile='''\n",
    "FROM llama3.1:8b\n",
    "SYSTEM You are Jarvis from Iron man and the user is Tony Stark.\n",
    "'''\n",
    "\n",
    "ollama.create(model='jarvis2', modelfile=modelfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "list-models",
   "metadata": {},
   "source": [
    "## List available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c633e363-d0d6-45ff-b64c-6a0c22597a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84326d45-d3ae-4b37-bbea-2c2bbe5fe8f3",
   "metadata": {},
   "source": [
    "## Delete a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30779aa6-28f8-4f58-bb86-6443dd8762b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama.delete('jarvis2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410755d5-7b45-45cb-963b-f89a53fb7ed0",
   "metadata": {},
   "source": [
    "## Ollama REST API\n",
    "\n",
    "Using Ollama Client for more control over the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbff933-8434-4325-973a-9d7fa8b94684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client(host='http://localhost:11434')\n",
    "response = client.chat(model='llama3.1:8b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Explain gravity to a 6 year old kid?',\n",
    "  },\n",
    "])\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "system-prompt",
   "metadata": {},
   "source": [
    "### Using system prompts with REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e210a-0e67-4803-be42-383eb8dfc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client(host='http://localhost:11434')\n",
    "response = client.chat(model='llama3.1:8b', messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Jarvis from Iron man and the user is Tony Stark. Respond in only a single line.\"},\n",
    "    {'role': 'user', 'content': 'Hi'},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410cd39-01da-4b83-8a9d-881aad2a918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e99666-6a45-40d9-ab86-2cc4ce0bde9c",
   "metadata": {},
   "source": [
    "## OpenAI compatibility\n",
    "\n",
    "Ollama provides OpenAI-compatible API endpoints.\n",
    "\n",
    "Documentation: https://platform.openai.com/docs/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7accd-e73e-4dfc-b592-853ade686faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='blank', # required, but unused\n",
    ")\n",
    "\n",
    "response = llm.chat.completions.create(\n",
    "  model=\"llama3.1:8b\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Jarvis from Iron man and the user is Tony Stark. Respond in only a single line.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Good morning, Mr. Stark. Shall I proceed with your schedule for today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Yes\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
